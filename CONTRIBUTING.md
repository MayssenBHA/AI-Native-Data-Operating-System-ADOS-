# Guide de Contribution - ADOS

Merci de votre int√©r√™t pour contribuer √† ADOS ! Ce guide vous aidera √† comprendre comment √©tendre et am√©liorer le syst√®me.

---

## üìã Table des Mati√®res

1. [Architecture du Code](#architecture-du-code)
2. [Ajouter un Data Product](#ajouter-un-data-product)
3. [Cr√©er une R√®gle de Validation](#cr√©er-une-r√®gle-de-validation)
4. [√âtendre le Knowledge Graph](#√©tendre-le-knowledge-graph)
5. [Ajouter un N≈ìud LangGraph](#ajouter-un-n≈ìud-langgraph)
6. [Tests et Qualit√©](#tests-et-qualit√©)
7. [Standards de Code](#standards-de-code)

---

## üèóÔ∏è Architecture du Code

### Principes de Design

1. **Modularit√©** : Chaque composant est ind√©pendant
2. **Testabilit√©** : Chaque module peut √™tre test√© isol√©ment
3. **Extensibilit√©** : Ajout facile de nouvelles fonctionnalit√©s
4. **Documentation** : Code auto-document√© avec docstrings

### Diagramme de D√©pendances

```
ados_main.py
    ‚îú‚îÄ‚îÄ modules/data_generator.py     (ind√©pendant)
    ‚îú‚îÄ‚îÄ modules/knowledge_graph.py    (d√©pend de data_generator)
    ‚îú‚îÄ‚îÄ modules/intent_compiler.py    (d√©pend de knowledge_graph)
    ‚îî‚îÄ‚îÄ modules/trust_layer.py        (d√©pend de knowledge_graph)

ados_interface.py ‚Üí importe tous les modules
```

---

## üÜï Ajouter un Data Product

### √âtape 1 : D√©finir le Sch√©ma

√âditez `modules/data_generator.py` :

```python
def generate_product_catalog_domain(self) -> pd.DataFrame:
    """
    G√©n√®re le Data Product: product_catalog_domain
    
    Returns:
        DataFrame avec colonnes: ID_Produit, Nom_Produit, Categorie, Prix_Unitaire
    """
    logger.info("G√©n√©ration du domaine Product Catalog...")
    
    categories = ["√âlectronique", "V√™tements", "Alimentation", "Maison", "Sport"]
    
    data = {
        "ID_Produit": self.product_ids,  # R√©utilise les IDs existants
        "Nom_Produit": [self.fake.catch_phrase() for _ in range(self.num_products)],
        "Categorie": np.random.choice(categories, self.num_products),
        "Prix_Unitaire": np.round(np.random.uniform(5, 500, self.num_products), 2),
        "Date_Creation": [self.fake.date_between(start_date='-5y', end_date='today') 
                          for _ in range(self.num_products)]
    }
    
    df = pd.DataFrame(data)
    output_path = self.output_dir / "product_catalog_domain.parquet"
    df.to_parquet(output_path, index=False)
    
    logger.info("‚úì product_catalog_domain.parquet cr√©√© (%d lignes)", len(df))
    return df
```

### √âtape 2 : Int√©grer dans `generate_all_domains()`

```python
def generate_all_domains(self) -> Dict[str, pd.DataFrame]:
    logger.info("=== G√©n√©ration de tous les Data Products ===")
    
    domains = {
        "customer": self.generate_customer_domain(),
        "logistics": self.generate_logistics_domain(),
        "sales": self.generate_sales_domain(),
        "product_catalog": self.generate_product_catalog_domain(),  # ‚¨ÖÔ∏è Ajout
    }
    
    logger.info("=== G√©n√©ration termin√©e ===")
    return domains
```

### √âtape 3 : Mettre √† Jour les M√©tadonn√©es

√âditez la m√©thode `get_metadata()` :

```python
def get_metadata(self) -> Dict:
    return {
        "num_customers": self.num_customers,
        "num_products": self.num_products,
        "num_transactions": self.num_transactions,
        "output_directory": str(self.output_dir),
        "files": [
            "customer_domain.parquet",
            "logistics_domain.parquet",
            "sales_domain.parquet",
            "product_catalog_domain.parquet",  # ‚¨ÖÔ∏è Ajout
        ]
    }
```

### √âtape 4 : Tester

```python
# Test du nouveau domaine
if __name__ == "__main__":
    simulator = DataMeshSimulator()
    product_catalog = simulator.generate_product_catalog_domain()
    print(product_catalog.head())
```

---

## ‚úÖ Cr√©er une R√®gle de Validation

### √âtape 1 : D√©finir la R√®gle

√âditez `modules/trust_layer.py` et ajoutez une nouvelle m√©thode :

```python
def _validate_performance_risk(self, sql_query: str) -> List[ValidationIssue]:
    """D√©tecte les requ√™tes potentiellement lentes"""
    issues = []
    
    # R√®gle 1: Jointures multiples sans LIMIT
    join_count = sql_query.upper().count("JOIN")
    has_limit = "LIMIT" in sql_query.upper()
    
    if join_count >= 3 and not has_limit:
        issues.append(ValidationIssue(
            severity=ValidationSeverity.WARNING,
            rule="performance_risk",
            message=f"Requ√™te avec {join_count} jointures sans LIMIT - risque de performance",
            suggestion="Ajoutez une clause LIMIT pour limiter les r√©sultats"
        ))
    
    # R√®gle 2: SELECT * sur fichiers volumineux
    if "SELECT *" in sql_query.upper() and not has_limit:
        issues.append(ValidationIssue(
            severity=ValidationSeverity.INFO,
            rule="performance_risk",
            message="SELECT * sans LIMIT - peut retourner beaucoup de donn√©es",
            suggestion="S√©lectionnez uniquement les colonnes n√©cessaires"
        ))
    
    return issues
```

### √âtape 2 : Int√©grer dans le Pipeline de Validation

Dans la m√©thode `validate_execution_plan()`, ajoutez :

```python
def validate_execution_plan(self, ...):
    # ... code existant ...
    
    # R√®gle 7: D√©tection de risques de performance
    issues.extend(self._validate_performance_risk(sql_query))
    
    # ... reste du code ...
```

### √âtape 3 : Tester la R√®gle

```python
# Test de la nouvelle r√®gle
trust_layer = TrustLayer(knowledge_graph=kg)

risky_sql = """
SELECT *
FROM 'data/customer_domain.parquet' AS c
JOIN 'data/sales_domain.parquet' AS s ON c.ID_Client = s.ID_Client
JOIN 'data/logistics_domain.parquet' AS l ON s.ID_Produit = l.ID_Produit
"""

passed, issues = trust_layer.validate_execution_plan(
    sql_query=risky_sql,
    required_files=["customer_domain", "sales_domain", "logistics_domain"],
    required_columns={}
)

for issue in issues:
    if issue.rule == "performance_risk":
        print(f"‚úì R√®gle d√©tect√©e: {issue.message}")
```

---

## üß† √âtendre le Knowledge Graph

### Ajouter une M√©thode de D√©couverte

√âditez `modules/knowledge_graph.py` :

```python
def discover_semantic_similarities(self, dataframes: Dict[str, pd.DataFrame]) -> List[Relationship]:
    """
    D√©couvre des relations bas√©es sur la similarit√© s√©mantique des noms de colonnes
    
    Uses:
        - Calcul de distance de Levenshtein
        - Embeddings de colonnes (optionnel)
    """
    relationships = []
    
    from difflib import SequenceMatcher
    
    files = list(dataframes.keys())
    
    for i, file1 in enumerate(files):
        for file2 in files[i+1:]:
            df1 = dataframes[file1]
            df2 = dataframes[file2]
            
            for col1 in df1.columns:
                for col2 in df2.columns:
                    # Calcul de similarit√©
                    similarity = SequenceMatcher(None, col1.lower(), col2.lower()).ratio()
                    
                    if similarity > 0.8 and similarity < 1.0:  # Presque identiques
                        rel = Relationship(
                            source_file=file1,
                            source_column=col1,
                            target_file=file2,
                            target_column=col2,
                            relationship_type="semantic_similarity",
                            confidence=similarity
                        )
                        relationships.append(rel)
                        logger.info("  Similarit√© trouv√©e: %s.%s ‚âà %s.%s (conf=%.2f)", 
                                  file1, col1, file2, col2, similarity)
    
    return relationships
```

### Int√©grer dans `discover_relationships()`

```python
def discover_relationships(self, dataframes: Dict[str, pd.DataFrame]) -> List[Relationship]:
    logger.info("D√©couverte des relations s√©mantiques...")
    
    self.relationships = []
    
    # M√©thode 1: Correspondances exactes et ID
    # ... code existant ...
    
    # M√©thode 2: Similarit√©s s√©mantiques
    semantic_rels = self.discover_semantic_similarities(dataframes)
    self.relationships.extend(semantic_rels)
    
    logger.info("‚úì %d relations d√©couvertes", len(self.relationships))
    return self.relationships
```

---

## üîÑ Ajouter un N≈ìud LangGraph

### √âtape 1 : D√©finir le N≈ìud

√âditez `modules/intent_compiler.py` :

```python
def _optimization_node(self, state: GraphState) -> GraphState:
    """
    N≈ìud 4: Optimisation de la requ√™te SQL
    
    R√¥le:
        - Analyser le plan SQL
        - Sugg√©rer des optimisations (index, r√©organisation)
        - R√©√©crire la requ√™te si n√©cessaire
    """
    logger.info("‚ö° Phase OPTIMIZATION: Analyse du plan")
    
    join_plan = state["join_plan"]
    if not join_plan:
        state["messages"].append("‚ö†Ô∏è Pas de plan √† optimiser")
        return state
    
    sql_query = join_plan.sql_query
    
    # Analyse simple: d√©tection de patterns non optimaux
    optimizations = []
    
    # Pattern 1: SELECT * ‚Üí SELECT colonnes sp√©cifiques
    if "SELECT *" in sql_query:
        optimizations.append("Remplacer SELECT * par s√©lection explicite de colonnes")
    
    # Pattern 2: Pas de LIMIT ‚Üí ajouter LIMIT
    if "LIMIT" not in sql_query.upper():
        optimizations.append("Ajouter une clause LIMIT pour limiter les r√©sultats")
    
    if optimizations:
        state["messages"].append(f"üí° Optimisations sugg√©r√©es: {len(optimizations)}")
        for opt in optimizations:
            logger.info("  - %s", opt)
    else:
        state["messages"].append("‚úì Requ√™te d√©j√† optimale")
    
    return state
```

### √âtape 2 : Int√©grer dans le Workflow

```python
def _build_workflow(self) -> StateGraph:
    workflow = StateGraph(GraphState)
    
    # Ajout des n≈ìuds
    workflow.add_node("discovery", self._discovery_node)
    workflow.add_node("planning", self._planning_node)
    workflow.add_node("optimization", self._optimization_node)  # ‚¨ÖÔ∏è Nouveau
    workflow.add_node("execution", self._execution_node)
    
    # D√©finition des ar√™tes
    workflow.set_entry_point("discovery")
    workflow.add_edge("discovery", "planning")
    workflow.add_edge("planning", "optimization")  # ‚¨ÖÔ∏è Nouveau chemin
    workflow.add_edge("optimization", "execution")
    workflow.add_edge("execution", END)
    
    return workflow
```

### √âtape 3 : Mettre √† Jour l'√âtat

Ajoutez le champ dans `GraphState` :

```python
class GraphState(TypedDict):
    user_intent: str
    knowledge_graph: LivingKnowledgeGraph
    data_dir: str
    
    discovery: Optional[DataDiscovery]
    join_plan: Optional[JoinPlan]
    optimizations: Optional[List[str]]  # ‚¨ÖÔ∏è Nouveau champ
    execution_result: Optional[ExecutionResult]
    
    validation_passed: bool
    validation_errors: List[str]
    messages: List[str]
```

---

## üß™ Tests et Qualit√©

### Structure de Test

Cr√©ez un fichier `tests/test_nouveau_composant.py` :

```python
import unittest
from modules.nouveau_composant import NouveauComposant

class TestNouveauComposant(unittest.TestCase):
    
    def setUp(self):
        """Pr√©paration avant chaque test"""
        self.composant = NouveauComposant()
    
    def test_fonctionnalite_basique(self):
        """Test de la fonctionnalit√© de base"""
        resultat = self.composant.execute()
        self.assertIsNotNone(resultat)
    
    def test_gestion_erreur(self):
        """Test de la gestion d'erreur"""
        with self.assertRaises(ValueError):
            self.composant.execute_avec_erreur()
    
    def tearDown(self):
        """Nettoyage apr√®s chaque test"""
        pass

if __name__ == '__main__':
    unittest.main()
```

### Ajouter au Test Global

√âditez `test_ados.py` et ajoutez :

```python
def test_nouveau_composant():
    """Test 7: Nouveau Composant"""
    print_section("TEST 7: Nouveau Composant")
    
    try:
        from modules.nouveau_composant import NouveauComposant
        
        composant = NouveauComposant()
        resultat = composant.execute()
        
        if resultat:
            print_success("Nouveau composant fonctionne")
            return True
        else:
            print_error("R√©sultat invalide")
            return False
            
    except Exception as e:
        print_error(f"Erreur: {e}")
        return False

# Ajouter au main
tests = [
    # ... tests existants ...
    ("Nouveau Composant", test_nouveau_composant),
]
```

---

## üìù Standards de Code

### Style Python

- **PEP 8** : Respect des conventions Python
- **Type Hints** : Utiliser les annotations de type
- **Docstrings** : Format Google/NumPy

### Exemple de Fonction Bien Document√©e

```python
def process_data(input_df: pd.DataFrame, 
                 column_name: str,
                 threshold: float = 0.5) -> pd.DataFrame:
    """
    Traite un DataFrame en filtrant selon un seuil.
    
    Args:
        input_df: DataFrame d'entr√©e √† traiter
        column_name: Nom de la colonne √† filtrer
        threshold: Valeur seuil pour le filtrage (default: 0.5)
    
    Returns:
        DataFrame filtr√© contenant uniquement les lignes sup√©rieures au seuil
    
    Raises:
        ValueError: Si column_name n'existe pas dans input_df
        TypeError: Si threshold n'est pas num√©rique
    
    Example:
        >>> df = pd.DataFrame({'score': [0.3, 0.7, 0.9]})
        >>> result = process_data(df, 'score', threshold=0.5)
        >>> len(result)
        2
    """
    if column_name not in input_df.columns:
        raise ValueError(f"Colonne '{column_name}' introuvable")
    
    if not isinstance(threshold, (int, float)):
        raise TypeError("threshold doit √™tre num√©rique")
    
    return input_df[input_df[column_name] > threshold]
```

### Logging

Utilisez le module logging de mani√®re coh√©rente :

```python
import logging

logger = logging.getLogger(__name__)

# Niveaux recommand√©s
logger.debug("Information d√©taill√©e pour debug")
logger.info("Information g√©n√©rale sur le flux")
logger.warning("Avertissement - comportement inattendu mais g√©r√©")
logger.error("Erreur - √©chec d'une op√©ration")
logger.critical("Erreur critique - arr√™t du syst√®me")
```

---

## üîÄ Workflow de Contribution

1. **Fork** le repository
2. **Cr√©er une branche** : `git checkout -b feature/nouvelle-fonctionnalite`
3. **D√©velopper** avec tests
4. **Tester** : `python test_ados.py`
5. **Commit** : `git commit -m "feat: ajout de X"`
6. **Push** : `git push origin feature/nouvelle-fonctionnalite`
7. **Pull Request** avec description d√©taill√©e

### Convention de Commits

```
feat: nouvelle fonctionnalit√©
fix: correction de bug
docs: modification de documentation
test: ajout/modification de tests
refactor: refactorisation du code
style: formatage du code
perf: am√©lioration de performance
```

---

## üìö Ressources

- **LangGraph** : https://langchain-ai.github.io/langgraph/
- **DuckDB** : https://duckdb.org/docs/
- **NetworkX** : https://networkx.org/documentation/
- **Chainlit** : https://docs.chainlit.io/

---

**Merci de contribuer √† ADOS ! üöÄ**
